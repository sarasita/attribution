{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from config.config import (PROCESSED_GMT_FILE,\n",
    "                           GRAPHICS_DIR, GRAPHICS_PAPER_MAIN_DIR, GRAPHICS_PAPER_APPENDIX_DIR, \n",
    "                           RESULTS_DIR,\n",
    "                           fontsize_medium,\n",
    "                           fontsize_small,\n",
    "                           fontsize_large, \n",
    "                           regions,\n",
    "                           region_naming_dict, \n",
    "                           population_shares, \n",
    "                           group_colors,\n",
    "                           uncertainty_color,\n",
    "                           sensitvitiy_color,\n",
    "                           symbols,\n",
    "                           EU27_ids,\n",
    "                           WID_DATA_PROCESSED\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "magicc_df = pd.read_csv(PROCESSED_GMT_FILE, index_col = 0)\n",
    "\n",
    "scaling_assumptions = ['CO2-scaling', 'equal-scaling', 'CH4-scaling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_attributed_gmt(magicc_df, groups, group_sizes):\n",
    "    # get total gmt increase since 1990 \n",
    "    delta_gmt = magicc_df[magicc_df.scenario == 'ssp245'].loc[:, '2020-01-01 00:00:00'].mean()-magicc_df[magicc_df.scenario == 'ssp245'].loc[:, '1990-01-01 00:00:00'].mean()\n",
    "    delta_gmt_bounds = np.quantile((magicc_df[magicc_df.scenario == 'ssp245'].loc[:, '2020-01-01 00:00:00'].values - magicc_df[magicc_df.scenario == 'ssp245'].loc[:, '1990-01-01 00:00:00'].values), q = [0.05, 0.95])\n",
    "    # for storing mean increase\n",
    "    group_deltas = np.zeros((len(scaling_assumptions), len(groups)))\n",
    "    # for storing 5th-95th increase \n",
    "    group_delta_bounds = np.zeros((len(scaling_assumptions), len(groups), 2))\n",
    "    \n",
    "    for i_assumption, scaling_assumption in enumerate(scaling_assumptions):\n",
    "        for i_group, group in enumerate(groups):\n",
    "            group_deltas[i_assumption, i_group] = magicc_df[magicc_df.scenario == 'ssp245'].loc[:, '2020-01-01 00:00:00'].mean() - magicc_df[magicc_df.scenario == f'World_{group}_{scaling_assumption}'].loc[:, '2020-01-01 00:00:00'].mean()\n",
    "            group_delta_bounds[i_assumption, i_group, :] = np.quantile((magicc_df[magicc_df.scenario == 'ssp245'].loc[:, '2020-01-01 00:00:00'].values - magicc_df[magicc_df.scenario == f'World_{group}_{scaling_assumption}'].loc[:, '2020-01-01 00:00:00'].values), q = [0.05, 0.95])\n",
    "    group_deltas_fair = [delta_gmt*i for i in group_sizes]\n",
    "    \n",
    "    return(group_deltas, group_delta_bounds, group_deltas_fair, delta_gmt, delta_gmt_bounds)\n",
    "\n",
    "def data_for_regional_gmt(magicc_df, regions, groups, group_sizes, population_shares):\n",
    "    # full warming since 1990\n",
    "    delta_gmt = magicc_df[magicc_df.scenario == 'ssp245'].loc[:, '2020-01-01 00:00:00'].mean()-magicc_df[magicc_df.scenario == 'ssp245'].loc[:, '1990-01-01 00:00:00'].mean()\n",
    "\n",
    "    # regional data frames\n",
    "    regional_group_deltas =  np.zeros((len(scaling_assumptions), len(regions), len(groups)))\n",
    "    regional_group_delta_bounds = np.zeros((len(scaling_assumptions), len(regions), len(groups), 2))\n",
    "    regional_group_deltas_equal = np.zeros((len(regions), len(groups)))\n",
    "\n",
    "    \n",
    "    for i_assumption, scaling_assumption in enumerate(scaling_assumptions):\n",
    "        for i_region, region in enumerate(regions):\n",
    "            for i_group, group in enumerate(groups): \n",
    "                regional_group_deltas[i_assumption, i_region, i_group] = magicc_df[magicc_df.scenario == 'ssp245'].loc[:, '2020-01-01 00:00:00'].mean() - magicc_df[magicc_df.scenario == f'{region}_{group}_{scaling_assumption}'].loc[:, '2020-01-01 00:00:00'].mean()\n",
    "                if not ((group == 'p0p100') & (scaling_assumption != 'equal-scaling')):\n",
    "                    regional_group_delta_bounds[i_assumption, i_region, i_group, :] = np.quantile(magicc_df[magicc_df.scenario == 'ssp245'].loc[:, '2020-01-01 00:00:00'].values - magicc_df[magicc_df.scenario == f'{region}_{group}_{scaling_assumption}'].loc[:, '2020-01-01 00:00:00'].values, q = [0.05, 0.95])\n",
    "            \n",
    "            regional_group_deltas_equal[i_region, :] = delta_gmt*population_shares[i_region]*group_sizes\n",
    "\n",
    "    return(regional_group_deltas, regional_group_delta_bounds, regional_group_deltas_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_deltas, group_delta_bounds, group_deltas_fair, delta_gmt, delta_gmt_bounds = data_for_attributed_gmt(magicc_df,\n",
    "                                                                                                           ['p90p100', 'p99p100', 'p999p100'],\n",
    "                                                                                                           np.array([0.1,0.01,0.001]))\n",
    "regional_group_deltas, regional_group_delta_bounds, regional_group_deltas_equal = data_for_regional_gmt(magicc_df, \n",
    "                                                                                                        regions,\n",
    "                                                                                                        ['p0p100', 'p90p100', 'p99p100', 'p999p100'],\n",
    "                                                                                                        np.array([1,0.1,0.01,0.001]),\n",
    "                                                                                                        population_shares)\n",
    "gmt_result_df = pd.DataFrame(columns = ['region', 'group', \n",
    "                                        'CO2-scaling_mean', 'CO2-scaling_lower-bound', 'CO2-scaling_upper-bound', \n",
    "                                        'equal-scaling_mean', 'equal-scaling_lower-bound', 'equal-scaling_upper-bound', \n",
    "                                        'equal_share',\n",
    "                                        'CH4-scaling_mean', 'CH4-scaling_lower-bound', 'CH4-scaling_upper-bound', ])\n",
    "\n",
    "row = 0\n",
    "gmt_result_df.loc[row, :] = ['global', 'historic', \n",
    "                             np.nan, np.nan, np.nan, \n",
    "                             delta_gmt, delta_gmt_bounds[0], delta_gmt_bounds[1], \n",
    "                             np.nan,\n",
    "                             np.nan, np.nan, np.nan,\n",
    "                            ]\n",
    "\n",
    "row += 1\n",
    "\n",
    "for i_group, group in enumerate(['top 10', 'top 1', 'top 0.1']): \n",
    "    gmt_result_df.loc[row, :] = ['global', group, \n",
    "                                group_deltas[0, i_group], group_delta_bounds[0, i_group, 0], group_delta_bounds[0, i_group, 1],\n",
    "                                group_deltas[1, i_group], group_delta_bounds[1, i_group, 0], group_delta_bounds[1, i_group, 1],\n",
    "                                group_deltas_fair[i_group],\n",
    "                                group_deltas[2, i_group], group_delta_bounds[2, i_group, 0], group_delta_bounds[2, i_group, 1],\n",
    "                                ]\n",
    "    row += 1\n",
    "\n",
    "for i_region, region in enumerate(regions):\n",
    "    for i_group, group in enumerate(['all', 'top 10', 'top 1', 'top 0.1']):\n",
    "        gmt_result_df.loc[row, :] = [region, group, \n",
    "                                        regional_group_deltas[0, i_region, i_group], regional_group_delta_bounds[0, i_region, i_group, 0], regional_group_delta_bounds[0, i_region, i_group, 1], \n",
    "                                        regional_group_deltas[1, i_region, i_group], regional_group_delta_bounds[1, i_region, i_group, 0], regional_group_delta_bounds[1, i_region, i_group, 1], \n",
    "                                        regional_group_deltas_equal[i_region, i_group],\n",
    "                                        regional_group_deltas[2, i_region, i_group], regional_group_delta_bounds[2, i_region, i_group, 0], regional_group_delta_bounds[2, i_region, i_group, 1]\n",
    "                                        ]\n",
    "        row += 1\n",
    "\n",
    "gmt_result_df.iloc[:, 2:] = gmt_result_df.iloc[:, 2:].astype(float).round(decimals = 3)\n",
    "\n",
    "# Path(RESULTS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "# gmt_result_df.to_csv(RESULTS_DIR / 'Attributed_GMT.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_mesmer-m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
